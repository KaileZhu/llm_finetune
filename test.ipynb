{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "在终端中运行以下命令，训练大概40min左右"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chmod +x train.sh\n",
    "./train.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "训练过程可以看到类似输出，loss逐渐下降，微调学习率也在下降（ds_config.json中设置的WarmupDecayLR的效果）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'loss': 4.9835, 'grad_norm': 0.0, 'learning_rate': 0, 'epoch': 0.04}                                           \n",
    "{'loss': 4.8253, 'grad_norm': 4.405423164367676, 'learning_rate': 9.971305595408895e-05, 'epoch': 0.09}         \n",
    "{'loss': 3.9028, 'grad_norm': 2.0647904872894287, 'learning_rate': 9.827833572453373e-05, 'epoch': 0.13}        \n",
    "{'loss': 3.8202, 'grad_norm': 3.0129778385162354, 'learning_rate': 9.684361549497848e-05, 'epoch': 0.17}        \n",
    "{'loss': 3.8426, 'grad_norm': 3.20343279838562, 'learning_rate': 9.540889526542324e-05, 'epoch': 0.21}          \n",
    "{'loss': 3.8415, 'grad_norm': 1.9773733615875244, 'learning_rate': 9.397417503586801e-05, 'epoch': 0.26}        \n",
    "{'loss': 3.7888, 'grad_norm': 2.0951831340789795, 'learning_rate': 9.253945480631277e-05, 'epoch': 0.3}         \n",
    "{'loss': 3.9397, 'grad_norm': 2.4926071166992188, 'learning_rate': 9.110473457675754e-05, 'epoch': 0.34}        \n",
    "{'loss': 3.8585, 'grad_norm': 2.0566821098327637, 'learning_rate': 8.96700143472023e-05, 'epoch': 0.39}         \n",
    "{'loss': 3.7841, 'grad_norm': 1.83524751663208, 'learning_rate': 8.823529411764706e-05, 'epoch': 0.43}          \n",
    "{'loss': 3.706, 'grad_norm': 1.8243296146392822, 'learning_rate': 8.680057388809183e-05, 'epoch': 0.47}         \n",
    "{'loss': 3.8282, 'grad_norm': 1.9283807277679443, 'learning_rate': 8.53658536585366e-05, 'epoch': 0.51}         \n",
    "{'loss': 3.7875, 'grad_norm': 1.9796059131622314, 'learning_rate': 8.393113342898136e-05, 'epoch': 0.56}        \n",
    "{'loss': 3.6784, 'grad_norm': 2.3480958938598633, 'learning_rate': 8.249641319942611e-05, 'epoch': 0.6}         \n",
    "{'loss': 3.8425, 'grad_norm': 2.2560489177703857, 'learning_rate': 8.106169296987089e-05, 'epoch': 0.64}        \n",
    "{'loss': 3.7645, 'grad_norm': 2.1410863399505615, 'learning_rate': 7.962697274031564e-05, 'epoch': 0.69}        \n",
    "{'loss': 3.73, 'grad_norm': 1.9889079332351685, 'learning_rate': 7.819225251076042e-05, 'epoch': 0.73}          \n",
    "{'loss': 3.5315, 'grad_norm': 1.9225326776504517, 'learning_rate': 7.675753228120517e-05, 'epoch': 0.77}        \n",
    "{'loss': 3.6367, 'grad_norm': 3.2905433177948, 'learning_rate': 7.532281205164993e-05, 'epoch': 0.81}           \n",
    "{'loss': 3.7057, 'grad_norm': 2.537975311279297, 'learning_rate': 7.38880918220947e-05, 'epoch': 0.86}          \n",
    "{'loss': 3.6549, 'grad_norm': 1.5785402059555054, 'learning_rate': 7.245337159253946e-05, 'epoch': 0.9}         \n",
    "{'loss': 3.6478, 'grad_norm': 2.4031765460968018, 'learning_rate': 7.101865136298422e-05, 'epoch': 0.94}        \n",
    "{'loss': 3.7109, 'grad_norm': 1.9929988384246826, 'learning_rate': 6.958393113342897e-05, 'epoch': 0.99}        \n",
    "{'loss': 3.2753, 'grad_norm': 2.0994067192077637, 'learning_rate': 6.814921090387375e-05, 'epoch': 1.03}        \n",
    "{'loss': 2.7037, 'grad_norm': 1.5692431926727295, 'learning_rate': 6.67144906743185e-05, 'epoch': 1.07}         \n",
    "{'loss': 2.5374, 'grad_norm': 2.1180508136749268, 'learning_rate': 6.527977044476328e-05, 'epoch': 1.11}        \n",
    "{'loss': 2.8278, 'grad_norm': 1.8666914701461792, 'learning_rate': 6.384505021520803e-05, 'epoch': 1.16}        \n",
    "{'loss': 2.7262, 'grad_norm': 1.8961942195892334, 'learning_rate': 6.241032998565281e-05, 'epoch': 1.2}         \n",
    "{'loss': 2.8378, 'grad_norm': 1.7014563083648682, 'learning_rate': 6.097560975609756e-05, 'epoch': 1.24}        \n",
    "{'loss': 2.6328, 'grad_norm': 1.765871524810791, 'learning_rate': 5.954088952654233e-05, 'epoch': 1.29}         \n",
    "{'loss': 2.8061, 'grad_norm': 1.8736974000930786, 'learning_rate': 5.810616929698709e-05, 'epoch': 1.33}        \n",
    "{'loss': 2.7628, 'grad_norm': 1.5451775789260864, 'learning_rate': 5.667144906743186e-05, 'epoch': 1.37}        \n",
    "{'loss': 2.6877, 'grad_norm': 2.127981424331665, 'learning_rate': 5.523672883787662e-05, 'epoch': 1.41}         \n",
    "{'loss': 2.6503, 'grad_norm': 2.483929395675659, 'learning_rate': 5.3802008608321376e-05, 'epoch': 1.46}        \n",
    "{'loss': 2.5183, 'grad_norm': 1.647443175315857, 'learning_rate': 5.236728837876615e-05, 'epoch': 1.5}          \n",
    "{'loss': 2.4353, 'grad_norm': 2.28279447555542, 'learning_rate': 5.0932568149210905e-05, 'epoch': 1.54}         \n",
    "{'loss': 2.7879, 'grad_norm': 2.163994073867798, 'learning_rate': 4.949784791965567e-05, 'epoch': 1.59}         \n",
    "{'loss': 2.674, 'grad_norm': 2.1242265701293945, 'learning_rate': 4.8063127690100434e-05, 'epoch': 1.63}        \n",
    "{'loss': 2.6449, 'grad_norm': 1.882237434387207, 'learning_rate': 4.66284074605452e-05, 'epoch': 1.67}          \n",
    "{'loss': 2.5549, 'grad_norm': 2.1271660327911377, 'learning_rate': 4.519368723098996e-05, 'epoch': 1.71}        \n",
    "{'loss': 2.6614, 'grad_norm': 2.9753880500793457, 'learning_rate': 4.375896700143472e-05, 'epoch': 1.76}        \n",
    "{'loss': 2.4219, 'grad_norm': 1.9853825569152832, 'learning_rate': 4.2324246771879484e-05, 'epoch': 1.8}        \n",
    "{'loss': 2.5714, 'grad_norm': 1.9522500038146973, 'learning_rate': 4.088952654232425e-05, 'epoch': 1.84}        \n",
    "{'loss': 2.806, 'grad_norm': 1.7837138175964355, 'learning_rate': 3.945480631276901e-05, 'epoch': 1.89}         \n",
    "{'loss': 2.6274, 'grad_norm': 2.4729552268981934, 'learning_rate': 3.802008608321377e-05, 'epoch': 1.93}        \n",
    "{'loss': 2.4436, 'grad_norm': 2.186725378036499, 'learning_rate': 3.6585365853658535e-05, 'epoch': 1.97}        \n",
    "{'loss': 2.2599, 'grad_norm': 1.602142572402954, 'learning_rate': 3.51506456241033e-05, 'epoch': 2.02}          \n",
    "{'loss': 1.6422, 'grad_norm': 2.7217836380004883, 'learning_rate': 3.3715925394548064e-05, 'epoch': 2.06}       \n",
    "{'loss': 1.6934, 'grad_norm': 3.0763559341430664, 'learning_rate': 3.228120516499283e-05, 'epoch': 2.1}         \n",
    "{'loss': 1.9787, 'grad_norm': 1.3903486728668213, 'learning_rate': 3.084648493543759e-05, 'epoch': 2.14}        \n",
    "{'loss': 1.7314, 'grad_norm': 2.2638742923736572, 'learning_rate': 2.9411764705882354e-05, 'epoch': 2.19}       \n",
    "{'loss': 1.566, 'grad_norm': 1.978325366973877, 'learning_rate': 2.7977044476327118e-05, 'epoch': 2.23}         \n",
    "{'loss': 1.6748, 'grad_norm': 1.9768247604370117, 'learning_rate': 2.6542324246771883e-05, 'epoch': 2.27}       \n",
    "{'loss': 1.7759, 'grad_norm': 2.25846004486084, 'learning_rate': 2.5107604017216647e-05, 'epoch': 2.32}         \n",
    "{'loss': 1.7469, 'grad_norm': 2.5877485275268555, 'learning_rate': 2.3672883787661408e-05, 'epoch': 2.36}       \n",
    "{'loss': 1.822, 'grad_norm': 1.9628933668136597, 'learning_rate': 2.223816355810617e-05, 'epoch': 2.4}          \n",
    "{'loss': 1.8742, 'grad_norm': 2.8355867862701416, 'learning_rate': 2.0803443328550933e-05, 'epoch': 2.44}       \n",
    "{'loss': 1.5126, 'grad_norm': 1.9370222091674805, 'learning_rate': 1.9368723098995698e-05, 'epoch': 2.49}       \n",
    "{'loss': 1.4505, 'grad_norm': 1.5190014839172363, 'learning_rate': 1.7934002869440462e-05, 'epoch': 2.53}       \n",
    "{'loss': 1.6585, 'grad_norm': 2.389292001724243, 'learning_rate': 1.6499282639885223e-05, 'epoch': 2.57}        \n",
    "{'loss': 1.742, 'grad_norm': 2.0531249046325684, 'learning_rate': 1.5064562410329986e-05, 'epoch': 2.62}        \n",
    "{'loss': 1.639, 'grad_norm': 1.5640772581100464, 'learning_rate': 1.3629842180774748e-05, 'epoch': 2.66}        \n",
    "{'loss': 1.604, 'grad_norm': 2.1148202419281006, 'learning_rate': 1.2195121951219513e-05, 'epoch': 2.7}         \n",
    "{'loss': 1.7203, 'grad_norm': 2.392643451690674, 'learning_rate': 1.0760401721664276e-05, 'epoch': 2.74}        \n",
    "{'loss': 1.7406, 'grad_norm': 2.392646074295044, 'learning_rate': 9.32568149210904e-06, 'epoch': 2.79}          \n",
    "{'loss': 1.5816, 'grad_norm': 2.2478280067443848, 'learning_rate': 7.890961262553803e-06, 'epoch': 2.83}        \n",
    "{'loss': 1.8403, 'grad_norm': 1.9995571374893188, 'learning_rate': 6.456241032998565e-06, 'epoch': 2.87}        \n",
    "{'loss': 1.8729, 'grad_norm': 1.8193557262420654, 'learning_rate': 5.021520803443329e-06, 'epoch': 2.92}        \n",
    "{'loss': 1.5593, 'grad_norm': 2.570446014404297, 'learning_rate': 3.586800573888092e-06, 'epoch': 2.96}         \n",
    "{'train_runtime': 2859.7151, 'train_samples_per_second': 3.912, 'train_steps_per_second': 0.244, 'train_loss': 2.741626185579532, 'epoch': 3.0}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
